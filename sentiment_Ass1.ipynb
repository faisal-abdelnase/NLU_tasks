{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzTQZ_itJ8hK"
      },
      "source": [
        "# Homework and bakeoff: Multi-domain sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "3NQZUsN0tWhj"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Christopher Potts\"\n",
        "__version__ = \"CS224u, Stanford, Spring 2023\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlaW7wHitWhk"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/main/hw_sentiment.ipynb)\n",
        "\n",
        "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTJj9DAEtWhk"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFC6A-N0tWhk"
      },
      "source": [
        "This homework and associated bakeoff are devoted to supervised sentiment analysis in a ternary label setting (positive, negative, neutral). Your ultimate goal is to develop systems that can make accurate predictions in multiple domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc8XD8krtWhl"
      },
      "source": [
        "The homework questions ask you to implement some baseline systems using DynaSent Round 1, DynaSent Round 2, and the Stanford Sentiment Treebank. The bakeoff challenge is to define a system that does well on the DynaSent test sets, the SST-3 test set, and a set of mystery examples that don't correspond to the DynaSent or SST-3 domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6pUtD9RtWhl"
      },
      "source": [
        "__Important methodological note:__ The DynaSent and SST-3 test sets are already publicly distributed, so we are counting on people not to cheat by developing their models on these test sets. You must do all your development without using these test sets at all, and then evaluate exactly once on the test set and turn in the results, with no further system tuning or additional runs. _Much of the scientific integrity of our field depends on people adhering to this honor code._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqBi-cDztWhl"
      },
      "source": [
        "This notebook briefly introduces our three development datasets, states the homework questions, and then provides guidance on the original system and associated bakeoff entry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsLcqWtBJ8hM"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "2nFUcNIhJ8hM"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Sort of randomly chosen import to see whether the requirements\n",
        "    # are met:\n",
        "    import datasets\n",
        "except ModuleNotFoundError:\n",
        "    !git clone https://github.com/cgpotts/cs224u/\n",
        "    !pip install -r cs224u/requirements.txt\n",
        "    import sys\n",
        "    sys.path.append(\"cs224u\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "pyAzJmyYSNMP"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJba1bGJ8hN"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGAwU8KmJ8hN"
      },
      "source": [
        "### DynaSent round 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnK3q1l0tWhm"
      },
      "source": [
        "The DynaSent dataset of [Potts, Wu, et al. 2021](https://aclanthology.org/2021.acl-long.186/) is a ternary sentiment benchmark consisting of two rounds (so far). The dataset is available on [Hugging Face](https://huggingface.co/datasets/dynabench/dynasent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR5LE8XctWhm"
      },
      "source": [
        "For Round 1, the authors collected sentences from the [Yelp Academic Dataset](https://www.yelp.com/dataset) that fooled a top-performing sentiment model but were intuitive for humans. The model was used only to heuristically find the examples. Crowdworkers multiply-labeled all of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxsP-cmGtWhm"
      },
      "source": [
        "The round contains a lot of metadata that could be useful for developing sentiment models. We will focus on just the sentences and labels, but you are free to make use of this additional metadata in developing uour system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9UcNgx_SZDG",
        "outputId": "42ec921c-cd1a-4cd6-91f4-75acedf44eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "dynasent_r1 = load_dataset(\"dynabench/dynasent\", 'dynabench.dynasent.r1.all', trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7iN05xzSkKo",
        "outputId": "d27e2880-d1fe-4a47-a14c-ab6259c4b768"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 80488\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 3600\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 3600\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "dynasent_r1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_iWixX6J8hO"
      },
      "source": [
        "Splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "RVjcdb_4SrS2"
      },
      "outputs": [],
      "source": [
        "def print_label_dist(dataset, labelname='gold_label', splitnames=('train', 'validation')):\n",
        "    for splitname in splitnames:\n",
        "        print(splitname)\n",
        "        dist = sorted(Counter(dataset[splitname][labelname]).items())\n",
        "        for k, v in dist:\n",
        "            print(f\"\\t{k:>14s}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3RQdIBRJ8hP",
        "outputId": "ab6a2dab-130d-406a-e041-9cc2a7a8f358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 14021\n",
            "\t       neutral: 45076\n",
            "\t      positive: 21391\n",
            "validation\n",
            "\t      negative: 1200\n",
            "\t       neutral: 1200\n",
            "\t      positive: 1200\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(dynasent_r1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4WFt0C6J8hP"
      },
      "source": [
        "### DynaSent round 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySxR6c2OtWhn"
      },
      "source": [
        "DynaSent Round 2 was created using different methods than Round 1. For Round 2, crowdworkers edited sentences from the Yelp Academic Dataset seeking to achieve a particular sentiment goal (e.g., expressing a positive sentiment) while fooling a top-performing model. This work was done on the [Dynabench](https://dynabench.org) platform. The hope is that this directly adversarial goal will lead to examples that are very hard for present-day models but intuitive for humans. All the examples were multiply-labeled by separate annotators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz3F_lviJ8hP",
        "outputId": "520c0f8d-5714-46fe-f4b7-a3a489df24cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "dynasent_r2 = load_dataset(\"dynabench/dynasent\", 'dynabench.dynasent.r2.all', trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up68q68dJ8hP",
        "outputId": "4287df18-4877-4097-9496-d632a5176180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 4579\n",
            "\t       neutral: 2448\n",
            "\t      positive: 6038\n",
            "validation\n",
            "\t      negative: 240\n",
            "\t       neutral: 240\n",
            "\t      positive: 240\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(dynasent_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeONNIJQJ8hP"
      },
      "source": [
        "### Stanford Sentiment Treebank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5R__m47tWhn"
      },
      "source": [
        "The [Stanford Sentiment Treebank (SST)](http://nlp.stanford.edu/sentiment/) of [Socher et al. 2013](https://aclanthology.org/D13-1170/) is a widely-used resource for evaluating supervised models. It consists of sentences from Rotten Tomatoes Movie Reviews (see [Pang and Lee's project page](https://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.home.html)). We will use the ternary version of the task (SST-3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lIUbBlGtWhn"
      },
      "source": [
        "SST examples are special in that they are labeled at the phrase-level as well as the sentence level, which provides very extensive and detailed supervision for sentiment. We will use only the sentence-level labels for the homework, but you are free to use the phrase-level labels as well in designing your original system. (To do this, you will need to get the dataset from the above project page, since the Hugging Face SST-3 we are using does not include these labels.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJROF2MaJ8hP",
        "outputId": "d4db4a54-e30e-44ab-bfc5-6ba688dbae25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "sst = load_dataset(\"SetFit/sst5\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw0I60nOJ8hQ",
        "outputId": "77df9754-2fa4-441d-d1a2-8f2d641b7ecb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 8544\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 1101\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 2210\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "sst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNdyn2KItWho"
      },
      "source": [
        "Out of the box, this is a five-way task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxmbH6qkJ8hQ",
        "outputId": "7536cb62-e73d-46b7-a3a9-bb7a93424a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 2218\n",
            "\t       neutral: 1624\n",
            "\t      positive: 2322\n",
            "\t very negative: 1092\n",
            "\t very positive: 1288\n",
            "validation\n",
            "\t      negative: 289\n",
            "\t       neutral: 229\n",
            "\t      positive: 279\n",
            "\t very negative: 139\n",
            "\t very positive: 165\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(sst, labelname='label_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "graFZCHbtWho"
      },
      "source": [
        "The above labels are not aligned with our ternary task, and the dataset distribution uses slightly different keys from those of DynaSent. The following code converts the dataset to SST-3 and also aligns the dataset keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "WDgWI8IzJ8hQ"
      },
      "outputs": [],
      "source": [
        "def convert_sst_label(s):\n",
        "    return s.split(\" \")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "UDT2FS0RJ8hQ"
      },
      "outputs": [],
      "source": [
        "for splitname in ('train', 'validation', 'test'):\n",
        "    dist = [convert_sst_label(s) for s in sst[splitname]['label_text']]\n",
        "    sst[splitname] = sst[splitname].add_column('gold_label', dist)\n",
        "    sst[splitname] = sst[splitname].add_column('sentence', sst[splitname]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-dl9asPJ8hQ",
        "outputId": "be6d7062-6989-48a9-95cf-0d91fa9b16e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 3310\n",
            "\t       neutral: 1624\n",
            "\t      positive: 3610\n",
            "validation\n",
            "\t      negative: 428\n",
            "\t       neutral: 229\n",
            "\t      positive: 444\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(sst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ERaj3cutWho"
      },
      "source": [
        "## Question 1: Linear classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHPgdpfuJ8hQ"
      },
      "source": [
        "Our first set of experiments will use simple linear classifiers with sparse representations derived from counting unigrams. These experiments will introduce some useful techniques and provide a baseline for original systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZLofGmLtWho"
      },
      "source": [
        "### Background: Feature functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBuWl44-tWhs"
      },
      "source": [
        "The following is a flexible format for writing feature functions in the context of scikit-learn modeling. The function maps a string to a count dictionary, using the simple procedure of splitting on whitespace and counting the resulting elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ItvMIMnPtWhs"
      },
      "outputs": [],
      "source": [
        "def unigrams_phi(s):\n",
        "    \"\"\"The basis for a unigrams feature function.\n",
        "\n",
        "    Downcases all tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : str\n",
        "        The example to represent\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Counter\n",
        "        A map from tokens (str) to their counts in `text`\n",
        "\n",
        "    \"\"\"\n",
        "    return Counter(s.lower().split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WUpSCZHtWhs"
      },
      "source": [
        "Quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Z3o1onOAtWhs",
        "outputId": "280d86ab-6523-45de-97ca-7b281e160dee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({\"here's\": 1,\n",
              "         'an': 2,\n",
              "         'example': 1,\n",
              "         'with': 1,\n",
              "         'emoticon': 1,\n",
              "         ':)!': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "unigrams_phi(\"Here's an example with an emoticon :)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl7V5UcctWht"
      },
      "source": [
        "### Background: Feature space vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKuHcqb-tWht"
      },
      "source": [
        "Functions like `unigrams_phi`  are just the __basis__ for feature representations. In truth, our models typically don't represent examples as dictionaries, but rather as vectors embedded in a matrix. In general, to manage the translation from dictionaries to vectors, we use [sklearn.feature_extraction.DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) instances. Here's a brief overview of how these work:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osZPCr-5tWht"
      },
      "source": [
        "To start, suppose that we had just two examples to represent, and our feature function mapped them to the following list of dictionaries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "DGFM3goYtWht"
      },
      "outputs": [],
      "source": [
        "train_feats = [\n",
        "    {'a': 1, 'b': 1},\n",
        "    {'b': 1, 'c': 2}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2kt9WVqtWht"
      },
      "source": [
        "Now we create a `DictVectorizer`. So that we can more easily inspect the resulting matrix, I've set `sparse=False`, so that the return value is a dense matrix. For real problems, you'll probably want to use `sparse=True`, as it will be vastly more efficient for the very sparse feature matrices that you are likely to be creating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "WJOGImUztWht"
      },
      "outputs": [],
      "source": [
        "vec = DictVectorizer(sparse=False)  # Use `sparse=True` for real problems!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD1DpaXrtWht"
      },
      "source": [
        "The `fit_transform` method maps our list of dictionaries to a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "DR1jjJ1FtWht"
      },
      "outputs": [],
      "source": [
        "X_train = vec.fit_transform(train_feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZfImzkGtWht"
      },
      "source": [
        "Here I'll create a `pd.Datafame` just to help us inspect `X_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "jvE0RCd8tWht",
        "outputId": "6ab724e5-35ff-40dc-87f7-60a6963de06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a    b    c\n",
              "0  1.0  1.0  0.0\n",
              "1  0.0  1.0  2.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfda0eab-3e0f-4550-913e-eeaecad14aef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfda0eab-3e0f-4550-913e-eeaecad14aef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfda0eab-3e0f-4550-913e-eeaecad14aef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfda0eab-3e0f-4550-913e-eeaecad14aef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e44397f0-6fdd-4d1b-939c-ee4c304dff5c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e44397f0-6fdd-4d1b-939c-ee4c304dff5c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e44397f0-6fdd-4d1b-939c-ee4c304dff5c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "pd.DataFrame(X_train, columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiwVNKGwtWht"
      },
      "source": [
        "Now we can see that, intuitively, the feature called \"a\" is embedded in the first column, \"b\" in the second column, and \"c\" in the third."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAhP4EzktWht"
      },
      "source": [
        "Now suppose we have some new test examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "rxn5fA9ftWht"
      },
      "outputs": [],
      "source": [
        "test_feats = [\n",
        "    {'a': 2, 'c': 1},\n",
        "    {'a': 4, 'b': 2, 'd': 1}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "068U_JpCtWhu"
      },
      "source": [
        "If we have trained a model on `X_train`, then it will not have any way to deal with this new feature \"d\". This shows that we need to embed `test_feats` in the same space as `X_train`. To do this, one just calls `transform` on the existing vectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "aiCl120MtWhu"
      },
      "outputs": [],
      "source": [
        "X_test = vec.transform(test_feats)  # Not `fit_transform`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "sKju4VjOtWhu",
        "outputId": "780f5803-95fc-45d7-c2a2-3ea1eef0f7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a    b    c\n",
              "0  2.0  0.0  1.0\n",
              "1  4.0  2.0  0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ff90e47-d725-4e99-9440-5536bfc07bc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff90e47-d725-4e99-9440-5536bfc07bc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ff90e47-d725-4e99-9440-5536bfc07bc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ff90e47-d725-4e99-9440-5536bfc07bc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59092626-112f-491a-94b1-2af431700f07\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59092626-112f-491a-94b1-2af431700f07')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59092626-112f-491a-94b1-2af431700f07 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 2.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "pd.DataFrame(X_test, columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFaGR1MNtWhu"
      },
      "source": [
        "The most common mistake with `DictVectorizer` is calling `fit_transform` on test examples. This will wipe out the existing representation scheme, replacing it with one that matches the test examples. That will happen silently, but then you'll find that the new representations are incompatible with the model you fit. This is likely to manifest itself as a `ValueError` relating to feature counts. Here's an example that might help you spot this if and when it arises in your own work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "gtUQ5ChqtWhu",
        "outputId": "2deb0056-7ec4-4901-fe45-cc304602ad28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: X has 4 features, but LogisticRegression is expecting 3 features as input.\n"
          ]
        }
      ],
      "source": [
        "toy_mod = LogisticRegression()\n",
        "\n",
        "vec = DictVectorizer(sparse=False)\n",
        "\n",
        "X_train = vec.fit_transform(train_feats)\n",
        "\n",
        "toy_mod.fit(X_train, [0, 1])\n",
        "\n",
        "# Here's the error! Don't use `fit_transform` again!\n",
        "# Use `transform`!\n",
        "X_test = vec.fit_transform(test_feats)\n",
        "\n",
        "try:\n",
        "    toy_mod.predict(X_test)\n",
        "except ValueError as err:\n",
        "    print(\"ValueError: {}\".format(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ViXJ19TtWhu"
      },
      "source": [
        "### Background: scikit-learn models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHrsCWhutWhu"
      },
      "source": [
        "scikit-learn is an amazing package with, among many other things, an incredible array of classifier model implementations. We're going to use a simple softmax classifier for this homework question, but you will find that you can swap in essentially any scikit-learn classifier and see how it does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44FXFpBNtWhu"
      },
      "source": [
        "The core rhythm for scikit-learn models:\n",
        "\n",
        "1. Instantiate the model with any hyperparamters.\n",
        "2. `fit`\n",
        "3. `predict`\n",
        "\n",
        "Here's a quick example that also shows off scikit-learn's functionality for creating synthetic datasets and random train/test splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "eOerp833tWhu"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_toy, y_toy = make_classification(\n",
        "    n_samples=200, n_classes=3,\n",
        "    n_informative=15, n_features=20,\n",
        "    weights=[0.2, 0.2, 0.6],\n",
        "    random_state=1)\n",
        "\n",
        "X_toy_train, X_toy_test, y_toy_train, y_toy_test = train_test_split(\n",
        "    X_toy, y_toy, test_size=0.20, stratify=y_toy, random_state=1)\n",
        "\n",
        "toymod = LogisticRegression(penalty='l2', C=1, fit_intercept=True)\n",
        "\n",
        "toymod.fit(X_toy_train, y_toy_train)\n",
        "\n",
        "toypreds = toymod.predict(X_toy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgC-HnR5tWhu"
      },
      "source": [
        "### Background: Classifier assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_Iaq81tWhv"
      },
      "source": [
        "When assessing a classifier, the best first step is usually to get a classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "LgPYkxmwtWhv",
        "outputId": "3459b8a6-b548-44bd-bbf1-354db278c9d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.444     0.500     0.471         8\n",
            "           1      0.444     0.500     0.471         8\n",
            "           2      0.909     0.833     0.870        24\n",
            "\n",
            "    accuracy                          0.700        40\n",
            "   macro avg      0.599     0.611     0.604        40\n",
            "weighted avg      0.723     0.700     0.710        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_toy_test, toypreds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAhzZlpPtWhv"
      },
      "source": [
        "In this course, we will generally focus in the __macro-average F1 score__ (macro avg above). This is simply the mean of the per-class F1 scores, without any attention paid to the overall size of the class. This is our default because, in NLP, we tend to care about small classes as much as (often more than) large classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkbRTP_3tWhv"
      },
      "source": [
        "The scikit-learn implementation of `macro_f1` can be finicky, so our course code provides a convenient wrapper:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "T62MJMSotWhv",
        "outputId": "fa723658-e373-41a8-e8be-983900870244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6035805626598466"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "utils.safe_macro_f1(y_toy_test, toypreds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--MTAbtWhv"
      },
      "source": [
        "Note: scikit-learn models have a `score` method. For classifiers, this is set to use `accuracy` by default:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "kG2I8vsMtWhv",
        "outputId": "df3dbc74-b661-4421-fa1f-e4f92f874861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "toymod.score(X_toy_test, y_toy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__K1tvWqtWhv"
      },
      "source": [
        "Accuracy generally isn't well-aligned with our goals, so we discourage use of this method (and of accuracy scores in general)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIHBkNwltWhv"
      },
      "source": [
        "scikit-learn also makes it very easy to perform automatic hyperparameter tuning. A quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "NmF5jEKAtWhv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'C': (0.1, 0.2, 0.3), 'fit_intercept': [True, False]}\n",
        "\n",
        "toymod_tuned = LogisticRegression()\n",
        "\n",
        "clf = GridSearchCV(toymod_tuned, params, scoring='f1_macro')\n",
        "\n",
        "_ = clf.fit(X_toy, y_toy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0AIt_utWhv"
      },
      "source": [
        "Here's the best model found by this search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "qI8cR8eStWhw",
        "outputId": "e43c20fe-6b31-4632-de9f-043b73df9ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.3, fit_intercept=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.3, fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.3, fit_intercept=False)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "clf.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDW5wNShtWhw"
      },
      "source": [
        "Because we set `scoring='f1_macro'`, the above model was selected using our favored classifier scoring metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "Eqnt_IQrtWhw",
        "outputId": "2bb8577a-50e5-4df4-9ab3-10b19ee15147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6943888670150135"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "clf.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut_jWQFItWhw"
      },
      "source": [
        "With this best model in hand, we can perform our usual assessment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "D9qv-bhrtWhw"
      },
      "outputs": [],
      "source": [
        "bestpreds = clf.best_estimator_.predict(X_toy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "OeDPFGnytWhw",
        "outputId": "12aef131-4245-4908-f60e-3157e473c87b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.750     0.600     0.667        10\n",
            "           1      0.750     0.750     0.750         8\n",
            "           2      0.833     0.909     0.870        22\n",
            "\n",
            "    accuracy                          0.800        40\n",
            "   macro avg      0.778     0.753     0.762        40\n",
            "weighted avg      0.796     0.800     0.795        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(bestpreds, y_toy_test, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuRHE5iwtWhw"
      },
      "source": [
        "### Task 1: Feature functions [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvi_XwoRtWhw"
      },
      "source": [
        "The tokenization scheme used by `unigrams_phi` is very basic and leads to unintuitive tokens with punctuation attached to them. Your task here is to complete `tweetgrams_phi`, which should lead to more intuitive results. The task is really just to use the NLTK [TweetTokenizer](https://www.nltk.org/api/nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer) in place of the simple whitespace tokenization of `unigrams_phi` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "nEErKdfMtWhw"
      },
      "outputs": [],
      "source": [
        "# Your `tweetgrams_phi` should tokenize data according to this tokenizer from NLTK:\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def tweetgrams_phi(s, **kwargs):\n",
        "    \"\"\"The basis for a feature function using `TweetTokenizer`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : str\n",
        "    kwargs : dict\n",
        "        Passed to `TweetTokenizer`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Counter\n",
        "        A map from tokens to their counts in `text`\n",
        "\n",
        "    \"\"\"\n",
        "    tokenizer = TweetTokenizer(**kwargs)\n",
        "    return Counter(tokenizer.tokenize(s))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IMM0XJTtWhw"
      },
      "source": [
        "Here's a test you can use to check that your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "l3-2P6_ntWhx"
      },
      "outputs": [],
      "source": [
        "def test_tweetgrams_phi(func):\n",
        "    examples = [\n",
        "        (\n",
        "            \"Here's an example with an emoticon :)\",\n",
        "            Counter({'an': 2, \"Here's\": 1, 'example': 1, 'with': 1, 'emoticon': 1, ':)': 1})\n",
        "        ),\n",
        "        (\n",
        "            \"The URL is https://pytorch.org!\",\n",
        "            Counter({'The': 1, 'URL': 1, 'is': 1, 'https://pytorch.org': 1, '!': 1})\n",
        "        )\n",
        "    ]\n",
        "    errcount = 0\n",
        "    for ex, expected in examples:\n",
        "        result = func(ex, preserve_case=True)\n",
        "        if result != expected:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{func.__name__}`: For input {ex}, \"\n",
        "                  f\"expected {expected} but got {result}\")\n",
        "    caps_ex = \"CAPS\"\n",
        "    caps_result = func(caps_ex, preserve_case=False)\n",
        "    caps_expected = Counter({\"caps\": 1})\n",
        "    if caps_result != caps_expected:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: For input {caps_ex}, \"\n",
        "              f\"expected {caps_expected} but got {caps_result}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"All tests passed for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "kSSnaSyUtWhx",
        "outputId": "e5cca598-fdff-48bc-871d-155fd125702d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed for `tweetgrams_phi`\n"
          ]
        }
      ],
      "source": [
        "test_tweetgrams_phi(tweetgrams_phi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uIlGqZGJ8hR"
      },
      "source": [
        "### Task 2: Model training [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik-cR_2itWhx"
      },
      "source": [
        "Your task is to complete `train_linear_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "rtEaAkHtStQg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "yfhADdcyJ8hR"
      },
      "outputs": [],
      "source": [
        "def train_linear_model(model, featfunc, train_dataset):\n",
        "    features = [featfunc(sentence) for sentence in train_dataset['sentence']]\n",
        "    vectorizer = DictVectorizer()\n",
        "    X_train = vectorizer.fit_transform(features)\n",
        "    y_train = train_dataset['gold_label']\n",
        "    model.fit(X_train, y_train)\n",
        "    return model, vectorizer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzjiMxbItWhx"
      },
      "source": [
        "You can use the following test to help ensure that your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "G9r-si52tWhx"
      },
      "outputs": [],
      "source": [
        "def test_train_linear_model(func):\n",
        "    train_dataset = {\n",
        "        'sentence': ['A A', 'A B', 'B B', 'B A', 'B'],\n",
        "        'gold_label': [0, 1, 0, 1, 1]}\n",
        "    def featfunc(s):\n",
        "        return Counter(s.split())\n",
        "    model = LogisticRegression()\n",
        "    result = func(model, featfunc, train_dataset)\n",
        "    if not isinstance(result, tuple) or len(result) != 2:\n",
        "        print(f\"Error for `{func.__name__}`: Incorrect return type\")\n",
        "        return\n",
        "    model, vectorizer = result\n",
        "    if not hasattr(vectorizer, 'vocabulary_'):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Second return value is not a trained vectorizer\")\n",
        "        return\n",
        "    if not hasattr(model, 'classes_'):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"First return value is not a trained classifier\")\n",
        "        return\n",
        "    print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "aKFX4sxdtWhx",
        "outputId": "5c03c331-5f6e-47d4-f5a6-3d9469517fa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `train_linear_model`\n"
          ]
        }
      ],
      "source": [
        "_ = test_train_linear_model(train_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDNTeC09tWhx"
      },
      "source": [
        "You can now very easily train models on our datasets. Quick example (this shouldn't take more than a couple of minutes to run even on a CPU):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "OQoCRRPHJ8hR"
      },
      "outputs": [],
      "source": [
        "lr_unigrams, vec_unigrams = train_linear_model(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    unigrams_phi, dynasent_r1['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTQL2tKBtWhx"
      },
      "source": [
        "### Task 3: Model assessment [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqE8leD-tWhy"
      },
      "source": [
        "Having now trained a model, we'd like to perform assessments on new data. Your task is to complete the wrapper function `assess_linear_model` to do this. The primary things you need to put into practice are (1) how to use a trained vectorizer on new data and (2) how to make predictions with your trained model. (Both of these steps are reviewed earlier in this notebook.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "GKa7uOwYJ8hR"
      },
      "outputs": [],
      "source": [
        "def assess_linear_model(model, featfunc, vectorizer, assess_dataset):\n",
        "    features = [featfunc(sentence) for sentence in assess_dataset['sentence']]\n",
        "    X_assess = vectorizer.transform(features)\n",
        "    y_true = assess_dataset['gold_label']\n",
        "    y_pred = model.predict(X_assess)\n",
        "    return classification_report(y_true, y_pred, digits=3)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfqcb-yXtWhy"
      },
      "source": [
        "Here's a quick test you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "5ww4lzw3tWhy"
      },
      "outputs": [],
      "source": [
        "def test_assess_linear_model(assessfunc, trainfunc):\n",
        "    train_dataset = {\n",
        "        'sentence': ['A A', 'A B', 'B B', 'B A', 'A', 'B'],\n",
        "        'gold_label': [0, 1, 0, 1, 0, 1]}\n",
        "    assess_dataset = {\n",
        "        'sentence': ['A C', 'B A'],\n",
        "        'gold_label': [0, 1]}\n",
        "    def featfunc(s):\n",
        "        return Counter(s.split())\n",
        "    model = LogisticRegression()\n",
        "    model, vectorizer = trainfunc(model, featfunc, train_dataset)\n",
        "    result = assessfunc(model, featfunc, vectorizer, assess_dataset)\n",
        "    errcount = 0\n",
        "    if len(vectorizer.vocabulary_) != 2:\n",
        "        print(f\"Error for `{assessfunc.__name__}`: Unexpected feature count\")\n",
        "        errcount += 1\n",
        "    if 'weighted avg' not in result:\n",
        "        print(f\"Error for `{assessfunc.__name__}`: Unexpected return value\")\n",
        "        errcount += 1\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{assessfunc.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "YPcX_ct9tWhy",
        "outputId": "d0bb8ca8-a96a-4dd7-9b89-e52350148aa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `assess_linear_model`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "test_assess_linear_model(assess_linear_model, train_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UjngdlLtWhy"
      },
      "source": [
        "If you trained a model `lr_unigrams` above, you can now easily assess it. An example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buRd2jpYJ8hR",
        "outputId": "4e2ea270-f0fb-498d-8e66-44e5c70be1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.755     0.365     0.492      1200\n",
            "     neutral      0.523     0.888     0.659      1200\n",
            "    positive      0.697     0.571     0.628      1200\n",
            "\n",
            "    accuracy                          0.608      3600\n",
            "   macro avg      0.658     0.608     0.593      3600\n",
            "weighted avg      0.658     0.608     0.593      3600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = assess_linear_model(\n",
        "    lr_unigrams,\n",
        "    unigrams_phi,\n",
        "    vec_unigrams,\n",
        "    dynasent_r1['validation'])\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezZAgHCNJ8hS"
      },
      "source": [
        "## Question 2: Transformer fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7soRgkcitWhy"
      },
      "source": [
        "We're now going to move into a more modern mode: fine-tuning pretrained components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLTBHaSgtWhy"
      },
      "source": [
        "We'll use BERT-mini (originally from [the BERT repo](https://github.com/google-research/bert)) for the homework so that we can rapdily develop prototypes. You can then consider scaling up to larger models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "sOGZlL8PtWhy"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsFLHAdttWhz"
      },
      "source": [
        "The `transformers` library does a lot of logging. To avoid ending up with a cluttered notebook, I am changing the logging level. You might want to skip this as you scale up to building production systems, since the logging is very good  it gives you a lot of insights into what the models and code are doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "LiFf-Cd0tWhz"
      },
      "outputs": [],
      "source": [
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVAxqWDVtWhz"
      },
      "source": [
        "Here we set ourselves up to use BERT-mini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "_aroZZpPtWhz"
      },
      "outputs": [],
      "source": [
        "weights_name = \"prajjwal1/bert-mini\"\n",
        "\n",
        "bert = AutoModel.from_pretrained(weights_name)\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(weights_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5MnMzFVtWhz"
      },
      "source": [
        "### Background: Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6HqiMvhtWhz"
      },
      "source": [
        "Tokenization in Transformer models is handled differently from tokenization in linear models of the sort we used in Question 1. For Transformer models, we need to use the tokenizer that comes with the model so that we reliably have embedding representations for every token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "fv0rEJIbtWhz"
      },
      "outputs": [],
      "source": [
        "example_text = \"Bert knows Snuffleupagus\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d1sh_uhtWhz"
      },
      "source": [
        "Here's a basic tokenization step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "xvNYHmAstWhz",
        "outputId": "053f4ac3-4c7b-4905-8ef9-28176111dbf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert', 'knows', 's', '##nu', '##ffle', '##up', '##ag', '##us']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "bert_tokenizer.tokenize(example_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUANSEButWhz"
      },
      "source": [
        "Notice that the tokenizer split \"Snuffleupagus\" into a bunch of subword tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9wpTWQvtWh0"
      },
      "source": [
        "The above use of the tokenizer, where we map from strings to lists of strings, is really for us humans. For modeling, the most important step for tokenization is mapping individual strings to sequences of integer ids. These ids key into the lowest embedding layer of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "AH9wYaXmtWh0",
        "outputId": "e044e772-08d3-4420-f5ea-ceecd2bf54d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 14324, 4282, 1055, 11231, 18142, 6279, 8490, 2271, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "ex_ids = bert_tokenizer.encode(example_text, add_special_tokens=True)\n",
        "\n",
        "ex_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOPxfCTtWh0"
      },
      "source": [
        "We can get map these indices back to \"words\" if we want:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "IaxjljiFtWh0",
        "outputId": "b34d716f-6843-4dc9-e6c8-b3172d9a37bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'bert',\n",
              " 'knows',\n",
              " 's',\n",
              " '##nu',\n",
              " '##ffle',\n",
              " '##up',\n",
              " '##ag',\n",
              " '##us',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "bert_tokenizer.convert_ids_to_tokens(ex_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caVRX-GetWh0"
      },
      "source": [
        "### Background: Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azrXwvF6tWh0"
      },
      "source": [
        "Having mapped our string to a list of tokens, we can use the `forward` method of the model to get representations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "GnshKr3ztWh0"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert(torch.tensor([ex_ids]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ5eGCT9tWh0"
      },
      "source": [
        "There are a lot of options for which representations to get. With the above call, we got the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "PCaR8asYtWh0",
        "outputId": "2eea637c-e5e4-446b-aa33-cc1507cc98ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "reps.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyMZsViItWh0"
      },
      "source": [
        "The value of `last_hidden_state` hidden state is the sequence of final output states from the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "1Jmp8GZztWh0",
        "outputId": "eb617793-1f69-4134-8921-9df29ad0e862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "reps.last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzHLTdcetWh1"
      },
      "source": [
        "This is: 1 example, 10 token representations, each one a 256 dimension vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM1gKpsOtWh1"
      },
      "source": [
        "The value of `pooler_output` is a set of currently random parameters sitting on top of the first output hidden state. You can see here that it is a single vector representation per example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "7k-l0oGitWh1",
        "outputId": "f951a255-90d3-448f-8daf-ddc31c61ac65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "reps.pooler_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogU1JEWvtWh1"
      },
      "source": [
        "I often feel unsure of precisely what this model component is. Here we can have a quick look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "xazJKPFutWh1",
        "outputId": "d5a358d8-6ab5-4ff6-968a-85fafa98a459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertPooler(\n",
              "  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (activation): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "bert.pooler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX-lC6eDtWh1"
      },
      "source": [
        "So this is a dense linear layer (a single matrix of weights) with a bias term, and a tanh activation function is applied to the output. We could put a classifier head on top of this if we wanted to, but we might have mixed feelings about being stuck with that tanh step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMOyYwPutWh1"
      },
      "source": [
        "### Background: Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA6KTK_LtWh1"
      },
      "source": [
        "Where examples from a single batch have different lengths, we need to mask the padded tokens to get the intended results from the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKY2xJJ5tWh1"
      },
      "source": [
        "For a quick example, here we process our full example from above and print out the first five values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "OxmXKgUhtWh1",
        "outputId": "c4b5acd0-1d56-4879-fb31-8693be986bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3763, -0.3209,  0.8817,  0.4568, -1.0314])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert(torch.tensor([ex_ids]))\n",
        "    print(reps.last_hidden_state[0][0][: 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUngd02tWh1"
      },
      "source": [
        "And now we do the same thing, but with masking of the final five positions to illustate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ur_zGTX-tWh1",
        "outputId": "ef7b6239-1db0-43d2-ed8f-c4f46949107c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1793, -0.8994,  0.9695,  0.9130, -0.7129])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    # Mask the last 5 tokens:\n",
        "    am = torch.tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n",
        "    maskreps = bert(torch.tensor([ex_ids]), attention_mask=am)\n",
        "    print(maskreps.last_hidden_state[0][0][: 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbkMBu79tWh1"
      },
      "source": [
        "### Task 1: Batch tokenization [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsQDEGpHtWh2"
      },
      "source": [
        "Your task here is to use the `batch_encode_plus` method for `bert_tokenizer` to tokenize a list of strings. You should complete `get_batch_token_ids` according to the specification in the doctring. All these steps can be handled with a single call to `batch_encode_plus`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "EYA8QoKztWh2"
      },
      "outputs": [],
      "source": [
        "def get_batch_token_ids(batch, tokenizer):\n",
        "    return tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sxgBn_rtWh2"
      },
      "source": [
        "Here's a test you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "-pk1kNImtWh2"
      },
      "outputs": [],
      "source": [
        "def test_get_batch_token_ids(func):\n",
        "    examples = [\n",
        "        \"Bert knows Snuffleupagus\",\n",
        "        \"ELMo knew Bert.\",\n",
        "        \"Buffalo \" * 520\n",
        "    ]\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-mini\")\n",
        "    result = func(examples, test_tokenizer)\n",
        "    errcount = 0\n",
        "    if 'attention_mask' not in result:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Attention mask was not returned\")\n",
        "    ids = result['input_ids']\n",
        "    if not isinstance(ids, torch.Tensor):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Return values are not tensors\")\n",
        "    if ids.shape[1] != 512:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Expected sequence length 512; got {ids.shape[1]}\")\n",
        "    if ids[0][0] != bert_tokenizer.cls_token_id:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Special tokens were not added\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "6L2eC0xQtWh2",
        "outputId": "3d13c344-d39e-45eb-bf34-5007cd051316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `get_batch_token_ids`\n"
          ]
        }
      ],
      "source": [
        "test_get_batch_token_ids(get_batch_token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4n3gBCxtWh2"
      },
      "source": [
        "### Task 2: Contextual representations [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd341stotWh2"
      },
      "source": [
        "This next task is not used directly in fine-tuning, but it should help ensure that you understand how BERT representations are created and how they need to be managed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9TuyVBItWh2"
      },
      "source": [
        "Your task is to complete `get_reps` so that, given a dataset (list of strings), it returns a single tensor in which each row is the output hidden state above the [CLS] token for that example. `gets_reps` has a batchsize argument that the user can manage depending on how much available memory they have and how large their model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "oXsrug3xtWh2"
      },
      "outputs": [],
      "source": [
        "def get_reps(dataset, model, tokenizer, batchsize=20):\n",
        "    reps = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(dataset), batchsize):\n",
        "            batch = dataset[i:i+batchsize]\n",
        "            inputs = get_batch_token_ids(batch, tokenizer)\n",
        "            output = model(**inputs).last_hidden_state[:, 0, :]\n",
        "            reps.append(output)\n",
        "    return torch.cat(reps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJxFnJhitWh2"
      },
      "source": [
        "Quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Rp6IYc7OtWh2"
      },
      "outputs": [],
      "source": [
        "def test_get_reps(func):\n",
        "    examples = [\"The cat slept.\", \"The bird chirped.\"] * 20\n",
        "    weights_name = \"prajjwal1/bert-mini\"\n",
        "    test_model = AutoModel.from_pretrained(weights_name)\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(weights_name)\n",
        "    result = func(examples, test_model, test_tokenizer, batchsize=2)\n",
        "    errcount = 0\n",
        "    if result.shape != (40, 256):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Expected shape {(40, 256)}, got {result.shape}\")\n",
        "    if round(result[0][0].item(), 2) != -0.64:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Representations seem to be incorrect\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "n1Xs6g2ntWh2",
        "outputId": "a6ca4708-da25-429d-8548-3cf4386e0721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `get_reps`\n"
          ]
        }
      ],
      "source": [
        "test_get_reps(get_reps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEaSOfAItWh3"
      },
      "source": [
        "### Task 3: Fine-tuning module [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97B8CASatWh3"
      },
      "source": [
        "We can now put the above together into a basic `nn.Module` that will fine-tune our BERT model. Most of the module is written for you. The pieces you need to implement:\n",
        "\n",
        "1. in the `init` methid, define `self.classifier_layer` using [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "2. Complete the `forward` method.\n",
        "\n",
        "Precise instructions are provided in the docstrings for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "DI_llzyUJ8hS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BertClassifierModule(nn.Module):\n",
        "    def __init__(self, n_classes, hidden_activation, weights_name=\"prajjwal1/bert-mini\"):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(weights_name)\n",
        "        self.hidden_dim = self.bert.config.hidden_size\n",
        "        self.classifier_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            hidden_activation,\n",
        "            nn.Linear(self.hidden_dim, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, indices, mask):\n",
        "        outputs = self.bert(input_ids=indices, attention_mask=mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.classifier_layer(cls_output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "8oLZPiaJtWh3"
      },
      "outputs": [],
      "source": [
        "bert_module = BertClassifierModule(n_classes=3, hidden_activation=nn.Tanh())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "ipML4qjxtWh3",
        "outputId": "37c13243-4c35-4b69-9f1b-1a1af4035fc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3605,  0.1968,  0.0889],\n",
              "        [ 0.4315,  0.0302, -0.0119]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "ids = get_batch_token_ids(\n",
        "    dynasent_r1['train']['sentence'][: 2],\n",
        "    bert_tokenizer)\n",
        "\n",
        "bert_module(ids['input_ids'], ids['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "ab_qLSq-tWh3"
      },
      "outputs": [],
      "source": [
        "def test_bert_classifier_module(moduleclass):\n",
        "    expected_out = 5\n",
        "    expected_hidden = 256\n",
        "    expected_activation = nn.ReLU()\n",
        "    mod = moduleclass(expected_out, expected_activation)\n",
        "    errcount = 0\n",
        "\n",
        "    # Basic layer structure:\n",
        "    if not hasattr(mod, \"classifier_layer\") or mod.classifier_layer is None:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Missing attribute `classifier_layer`\")\n",
        "        return\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            bert_module.classifier_layer[i]\n",
        "        except IndexError:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "                  f\"`classifier_layer` is not an `nn.Sequential` \"\n",
        "                  f\"and/or does not have the right structure\")\n",
        "    # Correct first layer dimensionality:\n",
        "    result_hidden = mod.classifier_layer[0].out_features\n",
        "    if result_hidden != expected_hidden:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected `classifier_layer` hidden dim {expected_hidden}, \"\n",
        "              f\"got {result_hidden}\")\n",
        "    # Correct activation:\n",
        "    result_activation = mod.classifier_layer[1].__class__.__name__\n",
        "    if result_activation != expected_activation.__class__.__name__:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Incorrect hidden activation\")\n",
        "    # Correct output dimensionality:\n",
        "    result_out = mod.classifier_layer[2].out_features\n",
        "    if result_out != expected_out:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected `classifier_layer` out dim {expected_out}, \"\n",
        "              f\"got {result_out}\")\n",
        "    # forward method:\n",
        "    ids = get_batch_token_ids([\"A B C\", \"A B\"], bert_tokenizer)\n",
        "    result = mod(ids['input_ids'], ids['attention_mask'])\n",
        "    if result.shape != (2, 5):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected output shape {(2, 5)}, got {result.shape}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{moduleclass.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "IXe34znstWh3",
        "outputId": "6a7aea0a-88a2-4526-9ec5-e446754cfd86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `BertClassifierModule`\n"
          ]
        }
      ],
      "source": [
        "test_bert_classifier_module(BertClassifierModule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVEAfeAftWh3"
      },
      "source": [
        "### Optional use: Classifier interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Yxq3UstWh3"
      },
      "source": [
        "The above module doesn't have functionality for processing data and fitting models. Our course code includes some general purpose code for adding these features. Here is an example that should work well with the module you wrote above. For more details on the design of these interfaces, see [tutorial_pytorch_models.ipynb](tutorial_pytorch_models.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "rfD8yC4AJ8hT"
      },
      "outputs": [],
      "source": [
        "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
        "\n",
        "class BertClassifier(TorchShallowNeuralClassifier):\n",
        "    def __init__(self, weights_name, *args, **kwargs):\n",
        "        self.weights_name = weights_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.weights_name)\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.params += ['weights_name']\n",
        "\n",
        "    def build_graph(self):\n",
        "        return BertClassifierModule(\n",
        "            self.n_classes_, self.hidden_activation, self.weights_name)\n",
        "\n",
        "    def build_dataset(self, X, y=None):\n",
        "        data = get_batch_token_ids(X, self.tokenizer)\n",
        "        if y is None:\n",
        "            dataset = torch.utils.data.TensorDataset(\n",
        "                data['input_ids'], data['attention_mask'])\n",
        "        else:\n",
        "            self.classes_ = sorted(set(y))\n",
        "            self.n_classes_ = len(self.classes_)\n",
        "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
        "            y = [class2index[label] for label in y]\n",
        "            y = torch.tensor(y)\n",
        "            dataset = torch.utils.data.TensorDataset(\n",
        "                data['input_ids'], data['attention_mask'], y)\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUBUlXcjtWh3"
      },
      "source": [
        "And here is a training run that should do pretty well for our problem.\n",
        "\n",
        "__Note__: This step should not be run on CPU machines. On Google Colab with a GPU, it will likely take about an hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "re8lzSepJ8hT"
      },
      "outputs": [],
      "source": [
        "bert_finetune = BertClassifier(\n",
        "    weights_name=\"prajjwal1/bert-mini\",\n",
        "    hidden_activation=nn.ReLU(),\n",
        "    eta=0.00005,          # Low learning rate for effective fine-tuning.\n",
        "    batch_size=8,         # Small batches to avoid memory overload.\n",
        "    gradient_accumulation_steps=4,  # Increase the effective batch size to 32.\n",
        "    early_stopping=True,  # Early-stopping\n",
        "    n_iter_no_change=5)   # params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlvq0G-PJ8hT",
        "outputId": "a2c47107-595c-4688-fef7-c46d4eec34b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stopping after epoch 11. Validation score did not improve by tol=1e-05 for more than 5 epochs. Final error is 485.40871281339787"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 17min 30s, sys: 19.5 s, total: 1h 17min 49s\n",
            "Wall time: 1h 18min 22s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "_ = bert_finetune.fit(\n",
        "    dynasent_r1['train']['sentence'],\n",
        "    dynasent_r1['train']['gold_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "WwwiIuKqJ8hT"
      },
      "outputs": [],
      "source": [
        "preds = bert_finetune.predict(sst['validation']['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Af7RAOJ8hT",
        "outputId": "a269b126-f695-40c0-e4c4-7fe44452aebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.558     0.621     0.588       428\n",
            "     neutral      0.323     0.328     0.325       229\n",
            "    positive      0.671     0.592     0.629       444\n",
            "\n",
            "    accuracy                          0.549      1101\n",
            "   macro avg      0.517     0.514     0.514      1101\n",
            "weighted avg      0.555     0.549     0.550      1101\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(sst['validation']['gold_label'], preds, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "YOblLwl3J8hU"
      },
      "outputs": [],
      "source": [
        "preds = bert_finetune.predict(dynasent_r1['validation']['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndDbPLY1b7lj",
        "outputId": "4c442bd9-d717-4adb-f6d7-bda2aa6cab32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.762     0.615     0.680      1200\n",
            "     neutral      0.661     0.825     0.734      1200\n",
            "    positive      0.730     0.690     0.710      1200\n",
            "\n",
            "    accuracy                          0.710      3600\n",
            "   macro avg      0.718     0.710     0.708      3600\n",
            "weighted avg      0.718     0.710     0.708      3600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(dynasent_r1['validation']['gold_label'], preds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTYnjAfPtWh4"
      },
      "source": [
        "## Question 3: Your original system [3 points]\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5aZQ7FZtWh4"
      },
      "source": [
        "Your task is to develop an original ternary sentiment classifier model. There are many options. The only rule:\n",
        "\n",
        "__You cannot make any use of the test sets for DynaSent-R1, DynaSent-R2, or SST-3, at any time during the course of development.__\n",
        "\n",
        "The integrity of the bakeoff depends on this rule being followed.\n",
        "\n",
        "It's fine to use the dev sets for system development  indeed, we encourage this.\n",
        "\n",
        "For system development, here are some relatively manageable ideas that you might try:\n",
        "\n",
        "* Different pretrained models. There are many models available on the [Hugging Face models hub](https://huggingface.co/models) that will be drop-in replacements for BERT-mini as we used it above.\n",
        "\n",
        "* Different fine-tuning regimes. We used the [CLS] token above. This doesn't make especially good use of the output states of the models. Pooling across these representtions (with sum, average, etc.) is likely to be better.\n",
        "\n",
        "* Different training regimes. You have three train sets at your disposal, and there may be other sentiment datasets that could contribute to making your system more robust in new domains.\n",
        "\n",
        "* Entirely different approaches. There is no requirement that you make use of any of the concepts from the homework questions in constructing your original system. Anything goes as long as you follow the one rule given above in bold.\n",
        "\n",
        "We want to emphasize that this needs to be an original system. It doesn't suffice to download code from the Web, retrain, and submit. You can build on others' code, but you have to do something new and meaningful with it. See the course website for additional guidance on how original systems will be evaluated.\n",
        "\n",
        "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "xRkcNL5YtWh4"
      },
      "outputs": [],
      "source": [
        "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
        "#   1) Textual description of your system.\n",
        "#   2) The code for your original system.\n",
        "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
        "\n",
        "# START COMMENT: Enter your system description in this cell.\n",
        "\n",
        "def foo(s):\n",
        "    return True\n",
        "\n",
        "# STOP COMMENT: Please do not remove this comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoDeKq7vtWh5"
      },
      "source": [
        "## Question 4: Bakeoff entry [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDagnXy2tWh5"
      },
      "source": [
        "The bakeoff dataset is available at\n",
        "\n",
        "https://web.stanford.edu/class/cs224u/data/cs224u-sentiment-test-unlabeled.csv\n",
        "\n",
        "This code should grab it for you and put it in `data/sentiment` if you are working in the cloud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "bf6w3q0LtWh5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "if not os.path.exists(os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\")):\n",
        "    os.makedirs(os.path.join('data', 'sentiment'), exist_ok=True)\n",
        "    wget.download('https://web.stanford.edu/class/cs224u/data/cs224u-sentiment-test-unlabeled.csv', out='data/sentiment/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE6_QPBWtWh5"
      },
      "source": [
        "If the above fails, you can just download the file and place it in `data/sentiment`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKgzRZjKtWh5"
      },
      "source": [
        "Once you have the file, you can load it to a `pd.DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "MF_HHnyStWh5"
      },
      "outputs": [],
      "source": [
        "bakeoff_df = pd.read_csv(\n",
        "    os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "yQGfhH-KtWh5",
        "outputId": "7ae16a5e-2671-45c7-a920-af1a2ec6aa45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   example_id                                           sentence\n",
              "0           0  This year we were at a restaurant that clearly...\n",
              "1           1                                        A long way.\n",
              "2           2  A friend and I went on a Thursday evening  aro...\n",
              "3           3  You'll love to say I used to be married to tha...\n",
              "4           4  I feel like any place I move will be a downgra..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-610bf2ec-c7db-4864-a359-916540f7f525\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>This year we were at a restaurant that clearly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A long way.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A friend and I went on a Thursday evening  aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You'll love to say I used to be married to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I feel like any place I move will be a downgra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-610bf2ec-c7db-4864-a359-916540f7f525')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-610bf2ec-c7db-4864-a359-916540f7f525 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-610bf2ec-c7db-4864-a359-916540f7f525');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67af0228-2f59-4dc5-8ca1-1d79beb1fd50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67af0228-2f59-4dc5-8ca1-1d79beb1fd50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67af0228-2f59-4dc5-8ca1-1d79beb1fd50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bakeoff_df",
              "summary": "{\n  \"name\": \"bakeoff_df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"example_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 866,\n        \"min\": 0,\n        \"max\": 2999,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          1801,\n          1190,\n          1817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"One down fall was the $385 bill for two.\",\n          \"We had lunch. The waiter mis-ordered two out of three meals. the food was good, not great.\",\n          \"a movie that will touch the hearts of both children and adults , as well as bring audiences to the edge of their seats .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "bakeoff_df.head()"
      ]
    },
    {
      "source": [
        "# @title example_id\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "bakeoff_df['example_id'].plot(kind='hist', bins=20, title='example_id')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "cellView": "form",
        "id": "YmWUAjpsRcvY",
        "outputId": "01bf7daf-b7af-47e8-9bd3-460e0723d0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEAltIsPtWh5"
      },
      "source": [
        "*To* enter the bakeoff, you simply need to use your original system to:\n",
        "\n",
        "1. Add a column named 'prediction' to `cs224u-sentiment-test-unlabeled.csv` with your model predictions (which are strings in {`positive`, `negative`, `neutral`}). The existing columns should remain.\n",
        "\n",
        "2. Save the file as `cs224u-sentiment-bakeoff-entry.csv`. Here is a good snippet of code for writing this file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "9UvgEbfYtWh5"
      },
      "outputs": [],
      "source": [
        "bakeoff_df = pd.read_csv(\n",
        "    os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))\n",
        "\n",
        "# Generating predictions using the trained model\n",
        "# Use the `predict` method of the `BertClassifier` instance:\n",
        "bakeoff_df['prediction'] = bert_finetune.predict(bakeoff_df['sentence'].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJJnoMfBtWh5"
      },
      "source": [
        "In particular, you need to be sure that `example_id` is a column rather than an index when read in by Pandas. Here is a quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "IByimvKitWh5"
      },
      "outputs": [],
      "source": [
        "def test_bakeoff_entry(filename=\"cs224u-sentiment-bakeoff-entry.csv\"):\n",
        "    gold_df = pd.read_csv(\n",
        "        os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))\n",
        "    entry_df = pd.read_csv(filename)\n",
        "\n",
        "    # Check that no required columns are missing:\n",
        "    expected_cols = {'example_id', 'sentence', 'prediction'}\n",
        "    missing_cols = expected_cols - set(entry_df.columns)\n",
        "    errcount = 0\n",
        "    if len(missing_cols) != 0:\n",
        "        errcount += 1\n",
        "        print(f\"Entry is missing required columns {missing_cols}\")\n",
        "        return\n",
        "\n",
        "    # Check that the predictions are in our space:\n",
        "    labels = {'positive', 'negative', 'neutral'}\n",
        "    predtypes = set(entry_df.prediction.unique())\n",
        "    unexpected = predtypes - labels\n",
        "    if len(unexpected) != 0:\n",
        "        errcount += 1\n",
        "        print(f\"Prediction column has unexpected values: {unexpected}\")\n",
        "\n",
        "    # Check that the dataset hasn't been rearranged:\n",
        "    for colname in ('example_id', 'sentence'):\n",
        "        if not entry_df[colname].equals(gold_df[colname]):\n",
        "            errcount += 1\n",
        "            print(f\"Entry is misaligned with test data on column {colname}\")\n",
        "\n",
        "    # Clean bill of health:\n",
        "    if errcount == 0:\n",
        "        print(\"No errors detected with `test_bakeoff_entry`.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "KnO6huoYtWh5",
        "outputId": "2d067a21-3a99-448b-fab5-75ae3b963f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entry is missing required columns {'prediction'}\n"
          ]
        }
      ],
      "source": [
        "test_bakeoff_entry(\"cs224u-sentiment-bakeoff-entry.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1g8oyXgtWh5"
      },
      "source": [
        "Submit the following files to Gradescope:\n",
        "\n",
        "* `hw_sentiment.ipynb` (this notebook)\n",
        "* `cs224u-sentiment-bakeoff-entry.csv` (bake-off output)\n",
        "\n",
        "Please make sure you use these filenames. The autograder looks for files with these names.\n",
        "\n",
        "You are not permitted to do any tuning of your system based on what you see in our bakeoff prediction file  you should not study that file in anyway, beyond perhaps checking that it contains what you expected it to contain. The upload function will do some additional checking to ensure that your file is well-formed.\n",
        "\n",
        "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
        "\n",
        "Late entries will be accepted, but they cannot earn the extra 0.5 points."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}